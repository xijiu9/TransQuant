Time 2022/12/10 20:39:21:
task_name stsb
train_file None
validation_file None
max_length 128
pad_to_max_length False
model_name_or_path bert-base-cased
use_slow_tokenizer False
per_device_train_batch_size 32
per_device_eval_batch_size 8
learning_rate 2e-05
weight_decay 0.0
num_train_epochs 3
max_train_steps 540
gradient_accumulation_steps 1
lr_scheduler_type SchedulerType.LINEAR
num_warmup_steps 0
output_dir ./test_glue_result_quantize/stsb/plt/choice=quantize_/seed=27
seed 27
push_to_hub False
hub_model_id None
hub_token None
checkpointing_steps None
resume_from_checkpoint None
with_tracking False
report_to all
ignore_mismatched_sizes False
arch BertForSequenceClassification
model_config quantize
choice ['quantize']
clip_lr 2e-05
clip_wd 0.0
ACT2FN gelu
SAQ False
rho 0.5
lmd 1.0
swa False
swa_start 6
swa_lr 0.05
swa_c_epochs 1
qa True
qw True
qg True
biased False
abits 3
wbits 4
biasbits 16
bbits 8
bwbits 8
persample False
hadamard False
biprecision True
twolayers_gradweight False
twolayers_gradinputt False
luq False
weight_quant_method lsq
input_quant_method ptq
learnable True
lsq_layerwise True
retain_large_value True
quantize_large_value False
cutood 40
clip_value 100.0
plt_debug False
change_type None
change_threshold 0
kd False
kd_path /
weight_norm False
epoch 0: {'pearson': 0.8313161303468583, 'spearmanr': 0.8260443390561252}
epoch 0: {'pearson': 0.5852670860000935, 'spearmanr': 0.5749069526668692}
epoch 1: {'pearson': 0.8580778717048095, 'spearmanr': 0.8524644924733027}
epoch 1: {'pearson': 0.7421306942445998, 'spearmanr': 0.7482424527623139}
epoch 2: {'pearson': 0.864979643188398, 'spearmanr': 0.8594083798152863}
epoch 2: {'pearson': 0.7506704365819751, 'spearmanr': 0.760729527193877}
